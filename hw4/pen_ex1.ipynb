{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Cluster 1\n",
    "c1_prior = 0.5\n",
    "c1_bern_p = 0.3\n",
    "c1_norm_mean = np.array([1, 1])\n",
    "c1_norm_cov = np.array([[2, 0.5], [0.5, 2]])\n",
    "c1_norm = multivariate_normal(c1_norm_mean, c1_norm_cov)\n",
    "\n",
    "# Cluster 2\n",
    "c2_prior = 0.5\n",
    "c2_bern_p = 0.7\n",
    "c2_norm_mean = np.array([0, 0])\n",
    "c2_norm_cov = np.array([[1.5, 1], [1, 1.5]])\n",
    "c2_norm = multivariate_normal(c2_norm_mean, c2_norm_cov)\n",
    "\n",
    "# Observations\n",
    "x1 = np.array([1, 0.6, 0.1])\n",
    "x2 = np.array([0, -0.4, 0.8])\n",
    "x3 = np.array([0, 0.2, 0.5])\n",
    "x4 = np.array([1, 0.4, -0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009986294880455089\n",
      "0.041866429997205\n",
      "0.1925895872206616 0.8074104127793383\n"
     ]
    }
   ],
   "source": [
    "# E step\n",
    "\n",
    "# x1\n",
    "x1_posterior_c1 = c1_bern_p*c1_norm.pdf(x1[1:3])*c1_prior\n",
    "x1_posterior_c2 = c2_bern_p*c2_norm.pdf(x1[1:3])*c2_prior\n",
    "x1_total_prob = x1_posterior_c1 + x1_posterior_c2\n",
    "x1_posterior_c1, x1_posterior_c2 = x1_posterior_c1/x1_total_prob, x1_posterior_c2/x1_total_prob\n",
    "\n",
    "# x2\n",
    "x2_posterior_c1 = (1-c1_bern_p)*c1_norm.pdf(x2[1:3])*c1_prior\n",
    "x2_posterior_c2 = (1-c2_bern_p)*c2_norm.pdf(x2[1:3])*c2_prior\n",
    "x2_total_prob = x2_posterior_c1 + x2_posterior_c2\n",
    "x2_posterior_c1, x2_posterior_c2 = x2_posterior_c1/x2_total_prob, x2_posterior_c2/x2_total_prob\n",
    "\n",
    "# x3\n",
    "x3_posterior_c1 = (1-c1_bern_p)*c1_norm.pdf(x3[1:3])*c1_prior\n",
    "x3_posterior_c2 = (1-c2_bern_p)*c2_norm.pdf(x3[1:3])*c2_prior\n",
    "x3_total_prob = x3_posterior_c1 + x3_posterior_c2\n",
    "x3_posterior_c1, x3_posterior_c2 = x3_posterior_c1/x3_total_prob, x3_posterior_c2/x3_total_prob\n",
    "\n",
    "# x4\n",
    "x4_posterior_c1 = c1_bern_p*c1_norm.pdf(x4[1:3])*c1_prior\n",
    "x4_posterior_c2 = c2_bern_p*c2_norm.pdf(x4[1:3])*c2_prior\n",
    "x4_total_prob = x4_posterior_c1 + x4_posterior_c2\n",
    "x4_posterior_c1, x4_posterior_c2 = x4_posterior_c1/x4_total_prob, x4_posterior_c2/x4_total_prob\n",
    "\n",
    "print(c1_bern_p*c1_norm.pdf(x1[1:3])*c1_prior)\n",
    "print(c2_bern_p*c2_norm.pdf(x1[1:3])*c2_prior)\n",
    "print(x1_posterior_c1, x1_posterior_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2340394840854108\n",
      "[0.026509   0.50712978]\n",
      "[[ 0.14136501 -0.10540546]\n",
      " [-0.10540546  0.0960526 ]]\n",
      "0.3861675546788702\n"
     ]
    }
   ],
   "source": [
    "# M step\n",
    "\n",
    "observations = np.array([x1[1:3], x2[1:3], x3[1:3], x4[1:3]]).T\n",
    "\n",
    "total_posteriors_c1 = x1_posterior_c1 + x2_posterior_c1 + x3_posterior_c1 + x4_posterior_c1\n",
    "total_posteriors_c2 = x1_posterior_c2 + x2_posterior_c2 + x3_posterior_c2 + x4_posterior_c2\n",
    "\n",
    "weights_c1 = np.array([x1_posterior_c1, x2_posterior_c1, x3_posterior_c1, x4_posterior_c1])/total_posteriors_c1\n",
    "weights_c2 = np.array([x1_posterior_c2, x2_posterior_c2, x3_posterior_c2, x4_posterior_c2])/total_posteriors_c2\n",
    "\n",
    "new_c1_bern_p = sum(np.array([1, 0, 0, 1])*weights_c1)\n",
    "new_c2_bern_p = sum(np.array([1, 0, 0, 1])*weights_c2)\n",
    "\n",
    "new_c1_norm_mean = np.average(observations, axis=1, weights=weights_c1)\n",
    "new_c2_norm_mean = np.average(observations, axis=1, weights=weights_c2)\n",
    "\n",
    "new_c1_norm_cov = np.cov(observations, aweights=weights_c1, ddof=0)\n",
    "new_c2_norm_cov = np.cov(observations, aweights=weights_c2, ddof=0)\n",
    "\n",
    "new_c1_prior = total_posteriors_c1/(total_posteriors_c1+total_posteriors_c2)\n",
    "new_c2_prior = total_posteriors_c2/(total_posteriors_c1+total_posteriors_c2)\n",
    "\n",
    "print(new_c1_bern_p)\n",
    "print(new_c1_norm_mean)\n",
    "print(new_c1_norm_cov)\n",
    "print(new_c1_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1:  0.08028950846197537\n",
      "C2:  0.9197104915380246\n"
     ]
    }
   ],
   "source": [
    "# Ex 2\n",
    "\n",
    "new_c1_norm = multivariate_normal(new_c1_norm_mean, new_c1_norm_cov)\n",
    "new_c2_norm = multivariate_normal(new_c2_norm_mean, new_c2_norm_cov)\n",
    "\n",
    "x_new = np.array([1, 0.3, 0.7])\n",
    "\n",
    "x_new_posterior_c1 = new_c1_bern_p*new_c1_norm.pdf(x_new[1:3])*new_c1_prior\n",
    "x_new_posterior_c2 = new_c2_bern_p*new_c2_norm.pdf(x_new[1:3])*new_c2_prior\n",
    "total_x_new_prob = x_new_posterior_c1 + x_new_posterior_c2\n",
    "x_new_posterior_c1, x_new_posterior_c2 = x_new_posterior_c1/total_x_new_prob, x_new_posterior_c2/total_x_new_prob\n",
    "\n",
    "print(\"C1: \", x_new_posterior_c1)\n",
    "print(\"C2: \", x_new_posterior_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1:  0.13296862745986288 0.8670313725401372\n",
      "X2:  0.8997775860290206 0.10022241397097947\n",
      "X3:  0.6657785222758356 0.3342214777241645\n",
      "X4:  0.01774039284027901 0.982259607159721\n"
     ]
    }
   ],
   "source": [
    "# Ex 3\n",
    "\n",
    "# x1\n",
    "new_x1_likelihood_c1 = new_c1_bern_p*new_c1_norm.pdf(x1[1:3])\n",
    "new_x1_likelihood_c2 = new_c2_bern_p*new_c2_norm.pdf(x1[1:3])\n",
    "new_x1_total_prob = new_x1_likelihood_c1 + new_x1_likelihood_c2\n",
    "new_x1_likelihood_c1, new_x1_likelihood_c2 = new_x1_likelihood_c1/new_x1_total_prob, new_x1_likelihood_c2/new_x1_total_prob\n",
    "\n",
    "# x2\n",
    "new_x2_likelihood_c1 = (1 - new_c1_bern_p)*new_c1_norm.pdf(x2[1:3])\n",
    "new_x2_likelihood_c2 = (1 - new_c2_bern_p)*new_c2_norm.pdf(x2[1:3])\n",
    "new_x2_total_prob = new_x2_likelihood_c1 + new_x2_likelihood_c2\n",
    "new_x2_likelihood_c1, new_x2_likelihood_c2 = new_x2_likelihood_c1/new_x2_total_prob, new_x2_likelihood_c2/new_x2_total_prob\n",
    "\n",
    "# x3\n",
    "new_x3_likelihood_c1 = (1 - new_c1_bern_p)*new_c1_norm.pdf(x3[1:3])\n",
    "new_x3_likelihood_c2 = (1 - new_c2_bern_p)*new_c2_norm.pdf(x3[1:3])\n",
    "new_x3_total_prob = new_x3_likelihood_c1 + new_x3_likelihood_c2\n",
    "new_x3_likelihood_c1, new_x3_likelihood_c2 = new_x3_likelihood_c1/new_x3_total_prob, new_x3_likelihood_c2/new_x3_total_prob\n",
    "\n",
    "# x4\n",
    "new_x4_likelihood_c1 = new_c1_bern_p*new_c1_norm.pdf(x4[1:3])\n",
    "new_x4_likelihood_c2 = new_c2_bern_p*new_c2_norm.pdf(x4[1:3])\n",
    "new_x4_total_prob = new_x4_likelihood_c1 + new_x4_likelihood_c2\n",
    "new_x4_likelihood_c1, new_x4_likelihood_c2 = new_x4_likelihood_c1/new_x4_total_prob, new_x4_likelihood_c2/new_x4_total_prob\n",
    "\n",
    "print(\"X1: \", new_x1_likelihood_c1, new_x1_likelihood_c2)\n",
    "print(\"X2: \", new_x2_likelihood_c1, new_x2_likelihood_c2)\n",
    "print(\"X3: \", new_x3_likelihood_c1, new_x3_likelihood_c2)\n",
    "print(\"X4: \", new_x4_likelihood_c1, new_x4_likelihood_c2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
