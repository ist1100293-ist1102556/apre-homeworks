\documentclass[12pt]{article}
\usepackage[paper=letterpaper,margin=2cm]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{newtxtext, newtxmath}
\usepackage{enumitem}
\usepackage{titling}
\usepackage[colorlinks=true]{hyperref}

\setlength{\droptitle}{-6em}

\begin{document}

\center
Aprendizagem 2023\\
Homework I -- Group 016\\
(ist1100293, ist1102556)\vskip 1cm

\large{\textbf{Part I}: Pen and paper}\normalsize

\begin{enumerate}[leftmargin=\labelsep]
\item Complete the given decision tree using Information gain with Shannon entropy ($\log_2$).
Consider that: i) a minimum of 4 observations is required to split an internal node, and
ii) decisions by ascending alphabetic order should be placed in case of ties.
    

\item Draw the training confusion matrix for the learnt decision tree.

\item Identify which class has the lowest training F1 score.

\item Considering $y_2$ to be ordinal, assess if $y_1$ and $y_2$ are correlated using the Spearman coefficient.
\begin{center}
    
    \begin{tabular}{|c | c | c | c | c|}
        \hline
        D & $y_1$ & $r_{y_1}$ & $y_2$ & $r_{y_2}$\\
        \hline
        $x_1$    & 0.24 & 3  & 1 & 8 \\
        $x_2$    & 0.06 & 2  & 2 & 11 \\
        $x_3$    & 0.04 & 1  & 0 & 3.5 \\
        $x_4$    & 0.36 & 5  & 0 & 3.5 \\
        $x_5$    & 0.32 & 4  & 0 & 3.5 \\
        $x_6$    & 0.68 & 10 & 2 & 11 \\
        $x_7$    & 0.9  & 12 & 0 & 3.5 \\
        $x_8$    & 0.76 & 11 & 2 & 11 \\
        $x_9$    & 0.46 & 7  & 1 & 8 \\
        $x_{10}$ & 0.62 & 9  & 0 & 3.5 \\
        $x_{11}$ & 0.44 & 6  & 1 & 8 \\
        $x_{12}$ & 0.52 & 8  & 0 & 3.5 \\
        \hline
    \end{tabular}

    \begin{equation}
        \begin{split}
            \textrm{Spearman}(y_1, y_2) & = \textrm{Pearson}(r_{y_1}, r_{y_2}) \\
            & = \frac{\sum (r_{y_1}-\overline{r_{y_1}})(r_{y_2}-\overline{r_{y_1}})}{\sqrt[]{\sum (r_{y_1}-\overline{r_{y_1}})^2}\sqrt[]{\sum (r_{y_2}-\overline{r_{y_2}})^2}} \\
            & = \frac{\sum r_{y_1}r_{y_2} - \frac{\sum r_{y_1} \sum r_{y_2}}{n}}{\sqrt{(\sum r_{y_1}^2-\frac{(\sum r_{y_1})^2}{n})(\sum r_{y_2}^2-\frac{(\sum r_{y_2})^2}{n })}}
        \end{split}
    \end{equation}

\end{center}
\paragraph{}Temos que: $\sum r_{y_1}r_{y_2} = 517.5$, $\sum r_{y_1} = 78$, $\sum r_{y_2} = 78$, $\sum r_{y_1}^2 = 650$, $\sum r_{y_2}^2 = 628.5$.
    \item Draw the class-conditional relative histograms of $y_1$ using 5 equally spaced bins in [0,1].
Challenge: find the root split using the discriminant rules from these empirical distributions.
\end{enumerate}

\large{\textbf{Part II}: Programming}\normalsize

\begin{enumerate}[leftmargin=\labelsep,resume]
\item Solution to the programming questions here.
\end{enumerate}

\vskip 1cm
\textbf{End note}: do not forget to also submit your Jupyter notebook

\end{document}
